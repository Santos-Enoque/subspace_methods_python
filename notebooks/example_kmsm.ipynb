{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import h5py\n",
    "import numpy as np\n",
    "from scipy.linalg import block_diag\n",
    "from sklearn.metrics.pairwise import rbf_kernel as _rbf_kernel\n",
    "from scipy.linalg import eigh\n",
    "from tqdm import tqdm as track\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.preprocessing import normalize as _normalize, LabelEncoder\n",
    "from scipy.linalg import block_diag\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "file_path = \"../data/Face_data.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base\n",
    "\n",
    "def mean_square_singular_values(matrix):\n",
    "    # Singular Value Decomposition\n",
    "    U, s, Vh = np.linalg.svd(matrix, full_matrices=False)\n",
    "    \n",
    "    # Mean square of the singular values\n",
    "    mean_square = np.mean(s ** 2)\n",
    "    \n",
    "    return mean_square\n",
    "\n",
    "\n",
    "##TODO - This function is not correct. It should be the mean square of the elements in the matrix resulting from Y @ X^T.\n",
    "def canonical_angle(X, Y):\n",
    "    return mean_square_singular_values(Y @ X.T)\n",
    "\n",
    "def canonical_angle_matrix(X, Y):\n",
    "    n_set_X, n_set_Y = len(X), len(Y)\n",
    "    C = np.empty((n_set_X, n_set_Y))\n",
    "\n",
    "    for x, sub_X in enumerate(X):\n",
    "        for y, sub_Y in enumerate(Y):\n",
    "            C[x, y] = canonical_angle(sub_X, sub_Y)\n",
    "\n",
    "    return C\n",
    "\n",
    "def _eigh(X, eigvals=None):\n",
    "    if eigvals != None:\n",
    "        e, V = eigh(X, eigvals=eigvals)\n",
    "    else:\n",
    "        e, V = np.linalg.eigh(X)\n",
    "\n",
    "    e, V = e[::-1], V[:, ::-1]\n",
    "\n",
    "    return e, V\n",
    "    \n",
    "    \n",
    "def _eigen_basis(X, eigvals=None):\n",
    "    try:\n",
    "        e, V = _eigh(X, eigvals=eigvals)\n",
    "    except np.linalg.LinAlgError:\n",
    "        # if it not converges, try with tiny salt\n",
    "        salt = 1e-8 * np.eye(X.shape[0])\n",
    "        e, V = eigh(X + salt, eigvals=eigvals)\n",
    "\n",
    "    return e, V\n",
    "\n",
    "\n",
    "def _get_eigvals(n, n_subdims, higher):\n",
    "    if n_subdims is None:\n",
    "        return None\n",
    "\n",
    "    if higher:\n",
    "        low = max(0, n - n_subdims)\n",
    "        high = n - 1\n",
    "    else:\n",
    "        low = 0\n",
    "        high = min(n - 1, n_subdims - 1)\n",
    "\n",
    "    return low, high \n",
    "\n",
    "\n",
    "\n",
    "def subspace_bases(X, n_subdims=None, higher=True, return_eigvals=False):\n",
    "    if X.shape[0] <= X.shape[1]:\n",
    "        eigvals = _get_eigvals(X.shape[0], n_subdims, higher)\n",
    "        # get eigenvectors of autocorrelation matrix X @ X.T\n",
    "        w, V = _eigen_basis(X @ X.T, eigvals=eigvals)\n",
    "    else:\n",
    "        # use linear kernel to get eigenvectors\n",
    "        A, w = dual_vectors(X.T @ X, n_subdims=n_subdims, higher=higher)\n",
    "        V = X @ A\n",
    "\n",
    "    if return_eigvals:\n",
    "        return V, w\n",
    "    else:\n",
    "        return V\n",
    "\n",
    "\n",
    "def dual_vectors(K, n_subdims=None, higher=True, eps=1e-6):\n",
    "    eigvals = _get_eigvals(K.shape[0], n_subdims, higher)\n",
    "    e, A = _eigen_basis(K, eigvals=eigvals)\n",
    "\n",
    "    e[(e < eps)] = eps\n",
    "\n",
    "    A = A / np.sqrt(e)\n",
    "\n",
    "    return A, e\n",
    "\n",
    "\n",
    "def cross_similarities(refs, inputs):\n",
    "    similarities = []\n",
    "    for _input in inputs:\n",
    "        sim = []\n",
    "        for ref in refs:\n",
    "            sim.append(mean_square_singular_values(ref.T @ _input))\n",
    "        similarities.append(sim)\n",
    "\n",
    "    similarities = np.array(similarities)\n",
    "\n",
    "    return similarities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "\n",
    "def calc_er(X, y, labels=None, data_type='S'):\n",
    "    _, _pred_class, mappings = _calc_preparations(X, labels, data_type)\n",
    "\n",
    "    if mappings is not None:\n",
    "        _y = np.array([mappings[v] for v in y])\n",
    "    else:\n",
    "        _y = y\n",
    "\n",
    "    er = (_pred_class == _y).mean()\n",
    "\n",
    "    return er\n",
    "\n",
    "\n",
    "def calc_eer(X, labels=None, data_type='S'):\n",
    "    _labels, _pred_class, _ = _calc_preparations(X, labels, data_type)\n",
    "    n_classes = len(np.unique(_labels))\n",
    "    print(_labels)\n",
    "    B = np.eye(n_classes)[_labels][:, _pred_class]\n",
    "\n",
    "    # make them 1D\n",
    "    _X = X.reshape(-1)\n",
    "    _B = B.reshape(-1)\n",
    "\n",
    "    # get sorted index regarding to data_type\n",
    "    if data_type == 'S':\n",
    "        sort_idx = np.argsort(_X)\n",
    "    else:\n",
    "        sort_idx = np.argsort(_X)[:, :, -1]\n",
    "\n",
    "    # number of positive/negative prediction\n",
    "    n_pos = _B[_B == 1].size\n",
    "    n_neg = _B.size - n_pos\n",
    "\n",
    "    # make _B sorted\n",
    "    _B = _B[sort_idx]\n",
    "\n",
    "    # False Acceptance Rate\n",
    "    far = 1 - np.cumsum(_B == 0) / n_neg\n",
    "    # False Rejection Rate\n",
    "    frr = np.cumsum(_B == 1) / n_pos\n",
    "\n",
    "    thresh_idx = np.abs(far - frr).argmin()\n",
    "    eer = (far[thresh_idx] + frr[thresh_idx]) / 2\n",
    "    thresh = _X[sort_idx][thresh_idx]\n",
    "\n",
    "    return eer, thresh\n",
    "\n",
    "\n",
    "def _calc_preparations(X, labels, data_type):\n",
    "    # check data_type\n",
    "    if data_type not in {'S', 'D'}:\n",
    "        raise ValueError('`data_type` must be \\'S\\' or \\'D\\'')\n",
    "\n",
    "    # check shape\n",
    "    if len(X.shape) != 2:\n",
    "        raise ValueError('`X` must be 2 dimensional matrix')\n",
    "    if labels is None:\n",
    "        _labels = np.arange(X.shape[1])\n",
    "        mappings = None\n",
    "    else:\n",
    "        classes = np.unique(labels)\n",
    "        mappings = np.stack((classes, np.arange(len(classes))), axis=1)\n",
    "        mappings = dict(mappings)\n",
    "        _labels = np.array([mappings[v] for v in labels])\n",
    "\n",
    "    if data_type == 'S':\n",
    "        idx = X.argmax(axis=1)\n",
    "    else:\n",
    "        idx = X.argmin(axis=1)\n",
    "\n",
    "    _pred_class = _labels[idx]\n",
    "\n",
    "    return _labels, _pred_class, mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel Methods\n",
    "\n",
    "def l2_kernel(X, Y):\n",
    "    XX = (X**2).sum(axis=0)[:, None]\n",
    "    YY = (Y**2).sum(axis=0)[None, :]\n",
    "    x = XX - 2 * (X.T @ Y) + YY\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def rbf_kernel(X, Y, sigma=None):\n",
    "    n_dims = X.shape[0]\n",
    "    if sigma is None:\n",
    "        sigma = np.sqrt(n_dims / 2)\n",
    "\n",
    "    x = l2_kernel(X, Y)\n",
    "\n",
    "    # gausiann kernel, (n_samples_X, n_samples_Y)\n",
    "    x = np.exp(-0.5 * x / (sigma**2))\n",
    "    return x\n",
    "\n",
    "\n",
    "def linear_kernel(X, Y):\n",
    "    return X.T @ Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Classes\n",
    "\n",
    "class SMBase(BaseEstimator, ClassifierMixin):\n",
    "    param_names = {'normalize', 'n_subdims'}\n",
    "\n",
    "    def __init__(self, n_subdims, normalize=False, faster_mode=False):\n",
    "        self.n_subdims = n_subdims\n",
    "        self.normalize = normalize\n",
    "        self.faster_mode = faster_mode\n",
    "        self.le = LabelEncoder()\n",
    "        self.dic = None\n",
    "        self.labels = None\n",
    "        self.n_classes = None\n",
    "        self._test_n_subdims = None\n",
    "        self.params = ()\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {name: getattr(self, name) for name in self.param_names}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "\n",
    "    def _prepare_X(self, X):\n",
    "        # normalize each vectors\n",
    "        if self.normalize:\n",
    "            X = [_normalize(_X) for _X in X]\n",
    "\n",
    "        X = [_X.T for _X in X]\n",
    "\n",
    "        return X\n",
    "\n",
    "    def _prepare_y(self, y):\n",
    "        # converted labels\n",
    "        y = self.le.fit_transform(y)\n",
    "        self.labels = y\n",
    "\n",
    "        # number of classes\n",
    "        self.n_classes = self.le.classes_.size\n",
    "\n",
    "        # number of data\n",
    "        self.n_data = len(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # ! X[i] will transposed for conventional\n",
    "        X = self._prepare_X(X)\n",
    "        y = self._prepare_y(y)\n",
    "\n",
    "        self._fit(X, y)\n",
    "\n",
    "    def _fit(self, X, y):\n",
    "        breakpoint()\n",
    "        dic = [subspace_bases(_X, self.n_subdims) for _X in X]\n",
    "        # dic,  (n_classes, n_dims, n_subdims)\n",
    "        dic = np.array(dic)\n",
    "        self.dic = dic\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.faster_mode and hasattr(self, 'fast_predict_proba'):\n",
    "            proba = self.fast_predict_proba(X)\n",
    "        else:\n",
    "            proba = self.predict_proba(X)\n",
    "\n",
    "        salt = 1e-3\n",
    "        assert proba.min() > 0.0 - salt, 'some probabilities are smaller than 0! min value is {}'.format(proba.min())\n",
    "        assert proba.max() < 1.0 + salt, 'some probabilities are bigger than 1! max value is {}'.format(proba.max())\n",
    "        proba = np.clip(proba, 0, 1)\n",
    "        return self.proba2class(proba)\n",
    "\n",
    "    def proba2class(self, proba):\n",
    "        pred = self.labels[np.argmax(proba, axis=1)]\n",
    "        return self.le.inverse_transform(pred)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = self._prepare_X([X])[0]\n",
    "        pred = self._predict_proba(X)\n",
    "        return pred\n",
    "\n",
    "    def _predict_proba(self, X):\n",
    "        raise NotImplementedError('_predict is not implemented')\n",
    "\n",
    "\n",
    "class KernelSMBase(SMBase):\n",
    "    param_names = {'normalize', 'n_subdims', 'sigma'}\n",
    "\n",
    "    def __init__(self, n_subdims, normalize=False, sigma=None, faster_mode=False):\n",
    "        super(KernelSMBase, self).__init__(n_subdims, normalize, faster_mode)\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def _fit(self, X, y):\n",
    "        coeff = []\n",
    "        for _X in track(X):\n",
    "            K = rbf_kernel(_X, _X, self.sigma)\n",
    "            _coeff, _ = dual_vectors(K, self.n_subdims)\n",
    "            coeff.append(_coeff)\n",
    "\n",
    "        self.dic = list(zip(X, coeff))\n",
    "\n",
    "\n",
    "class MSMInterface(object):\n",
    "    def predict_proba(self, X):\n",
    "        X = self._prepare_X(X)\n",
    "\n",
    "        pred = []\n",
    "        for _X in X:\n",
    "            gramians = self._get_gramians(_X)\n",
    "            c = [mean_square_singular_values(g) for g in gramians]\n",
    "            pred.append(c)\n",
    "        return np.array(pred)\n",
    "\n",
    "    def _get_gramians(self, X):\n",
    "        raise NotImplementedError('_get_gramians is not implemented')\n",
    "        \n",
    "    @property\n",
    "    def test_n_subdims(self):\n",
    "        if self._test_n_subdims is None:\n",
    "            return self.n_subdims\n",
    "        return self._test_n_subdims\n",
    "    \n",
    "    @test_n_subdims.setter\n",
    "    def test_n_subdims(self, v):\n",
    "        assert isinstance(v, int)\n",
    "        self._test_n_subdims = v\n",
    "        \n",
    "    @test_n_subdims.deleter\n",
    "    def test_n_subdims(self):\n",
    "        self._test_n_subdims = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMSM iMPLEMENTATION\n",
    "\n",
    "\n",
    "class KernelMSM(MSMInterface, KernelSMBase):\n",
    "    def _get_gramians(self, X):\n",
    "        K = rbf_kernel(X, X, self.sigma)\n",
    "        in_coeff, _ = dual_vectors(K, self.test_n_subdims)\n",
    "        \n",
    "        gramians = []\n",
    "        for i in range(self.n_data):\n",
    "            ref_X, ref_coeff = self.dic[i]\n",
    "            _K = rbf_kernel(ref_X, X, self.sigma)\n",
    "            S = ref_coeff.T.dot(_K.dot(in_coeff))\n",
    "            gramians.append(S)\n",
    "        return np.array(gramians)\n",
    "\n",
    "\n",
    "    def fast_predict_proba(self, X):\n",
    "        n_input = len(X)\n",
    "        n_ref =  len(self.dic)\n",
    "        X = self._prepare_X(X)\n",
    "        \n",
    "        ref_Xs, ref_coeffs = [], []\n",
    "        for ref_X, ref_coeff in self.dic:\n",
    "            ref_Xs.append(ref_X)\n",
    "            ref_coeffs.append(ref_coeff)\n",
    "    \n",
    "        ref_mappings = np.array([i for i in range(len(ref_Xs)) for _ in range(ref_coeffs[i].shape[1])])\n",
    "        ref_Xs = np.hstack(ref_Xs)\n",
    "        ref_coeffs = block_diag(*ref_coeffs)\n",
    "        \n",
    "        in_coeffs = []\n",
    "        for _X in X:\n",
    "            K = rbf_kernel(_X, _X, self.sigma)\n",
    "            in_coeff, _ = dual_vectors(K, self.test_n_subdims)\n",
    "            in_coeffs.append(in_coeff)\n",
    "        in_mappings = np.array([i for i in range(n_input) for _ in range(in_coeffs[i].shape[1])])\n",
    "        in_Xs = np.hstack(X)\n",
    "        in_coeffs = block_diag(*in_coeffs)\n",
    "        \n",
    "        K = rbf_kernel(in_Xs, ref_Xs, self.sigma)\n",
    "        del ref_Xs, in_Xs\n",
    "        \n",
    "        S = in_coeffs.T.dot(K).dot(ref_coeffs)\n",
    "        del in_coeffs, ref_coeffs, K\n",
    "        \n",
    "        # Split matrix into (n_input x n_ref) blocks\n",
    "        in_split = np.where(np.diff(np.pad(in_mappings, (1, 0), 'constant')))[0]\n",
    "        ref_split = np.where(np.diff(np.pad(ref_mappings, (1, 0), 'constant')))[0]\n",
    "        S = [np.hsplit(_S, ref_split) for _S in np.vsplit(S, in_split)]\n",
    "        \n",
    "        vmssv = np.vectorize(lambda i, j: mean_square_singular_values(S[i][j]))\n",
    "        pred = vmssv(*np.meshgrid(np.arange(n_input), np.arange(n_ref))).T\n",
    "        \n",
    "        del S, X\n",
    "        return np.array(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and Evaluate The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1000.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 7 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 1 1 1 4 1 1 4 1 1 1 1 1 1 1 1 1 7 1 1 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 6 2 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 3 3 3 3 3 3 3 3 3 3 1 3 3 3 3 3 3 3 4 4 4 4\n",
      " 4 4 4 4 4 4 0 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 8 5 8 5 5 5 5 5 5 8 5 8 8 5 5 9 5 5 5 5 5 8 5 5 6 6 6 6 6 5\n",
      " 6 6 6 6 6 6 6 9 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 4 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 0 7 7 7 7 7 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 6 6 6 9 9 9 9 9 9\n",
      " 9 9 6 9 9 9 9 6 9 9 9 9 6 6 6 9 6 6 6 9 9 9 9 9 9 9 9]\n",
      "true: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 9 9 9 9 9 9 9 9 9\n",
      " 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "accuracy: 0.9138888888888889\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_data(file_name):\n",
    "    with h5py.File(file_name, \"r\") as f:\n",
    "        # Extract the data from the file\n",
    "        train_X = np.array(f[\"X1\"])\n",
    "        train_y = np.arange(len(train_X))\n",
    "        test_X = np.array(f[\"X2\"])\n",
    "        test_X = test_X.reshape(-1, test_X.shape[-2], test_X.shape[-1])\n",
    "        test_y = np.array([[i] * 36 for i in range(10)]).flatten()\n",
    "\n",
    "    return train_X, train_y, test_X, test_y\n",
    "\n",
    "train_X, train_y, test_X, test_y = load_data(file_path)\n",
    "\n",
    "model = KernelMSM(n_subdims=5, sigma=100, faster_mode=True)\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "pred = model.predict(test_X)\n",
    "print(f\"pred: {pred}\\ntrue: {test_y}\\naccuracy: {(pred == test_y).mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
