{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape: torch.Size([60000, 1, 28, 28])\n",
      "Train labels shape: torch.Size([60000])\n",
      "Test images shape: torch.Size([10000, 1, 28, 28])\n",
      "Test labels shape: torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=len(trainset), shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=len(testset), shuffle=False)\n",
    "\n",
    "# Function to convert DataLoader object to tensor\n",
    "def loader_to_tensor(dataloader):\n",
    "    dataiter = iter(dataloader)\n",
    "    images, labels = next(dataiter)\n",
    "    return images, labels\n",
    "\n",
    "# Get the entire dataset\n",
    "train_images, train_labels = loader_to_tensor(trainloader)\n",
    "test_images, test_labels = loader_to_tensor(testloader)\n",
    "\n",
    "# Check the shape of the tensors\n",
    "print(\"Train images shape:\", train_images.shape)  # Should print torch.Size([60000, 1, 28, 28])\n",
    "print(\"Train labels shape:\", train_labels.shape)  # Should print torch.Size([60000])\n",
    "print(\"Test images shape:\", test_images.shape)    # Should print torch.Size([10000, 1, 28, 28])\n",
    "print(\"Test labels shape:\", test_labels.shape)    # Should print torch.Size([10000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [5923, 1, 28, 28] at entry 0 and [6742, 1, 28, 28] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3310/2288986125.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msorted_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtrain_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msort_images_by_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mtest_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msort_images_by_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3310/2288986125.py\u001b[0m in \u001b[0;36msort_images_by_labels\u001b[0;34m(images, labels, n_classes)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Combine sorted image tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0msorted_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msorted_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [5923, 1, 28, 28] at entry 0 and [6742, 1, 28, 28] at entry 1"
     ]
    }
   ],
   "source": [
    "\n",
    "# Sort images by labels\n",
    "def sort_images_by_labels(images, labels, n_classes=10):\n",
    "    sorted_images = [[] for _ in range(n_classes)]\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        label = labels[i]\n",
    "        image = images[i]\n",
    "        sorted_images[label].append(image)\n",
    "    \n",
    "    # Convert lists to tensors\n",
    "    for i in range(n_classes):\n",
    "        sorted_images[i] = torch.stack(sorted_images[i])\n",
    "    \n",
    "    # Combine sorted image tensors\n",
    "    sorted_tensor = torch.stack(sorted_images)\n",
    "    \n",
    "    return sorted_tensor\n",
    "\n",
    "train_sorted = sort_images_by_labels(train_images, train_labels)\n",
    "test_sorted = sort_images_by_labels(test_images, test_labels)\n",
    "\n",
    "print(\"Train sorted shape:\", train_sorted.shape)  # Should print torch.Size([10, n_of_images_per_class, 1, 28, 28])\n",
    "print(\"Test sorted shape:\", test_sorted.shape)    # Should print torch.Size([10, n_of_images_per_class, 1, 28, 28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
